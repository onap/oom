{
  "comments": [
    {
      "key": {
        "uuid": "01a04862_88933ace",
        "filename": "kubernetes/dcaemod/components/dcaemod-designtool/templates/service.yaml",
        "patchSetId": 2
      },
      "lineNbr": 19,
      "author": {
        "id": 4965
      },
      "writtenOn": "2020-02-21T23:46:38Z",
      "side": 1,
      "message": "we have helm templates for services now. Please use them.\nYou can find an example here:\nhttps://gerrit.onap.org/r/#/c/oom/+/101749/",
      "revId": "716cb4803746cf62f10eb194b0f416bde861ca4e",
      "serverId": "14b4e41f-c4e3-4fb9-9955-6a9b5656895a",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "4bafda3e_81ae8b66",
        "filename": "kubernetes/dcaemod/components/dcaemod-designtool/templates/service.yaml",
        "patchSetId": 2
      },
      "lineNbr": 19,
      "author": {
        "id": 511
      },
      "writtenOn": "2020-02-26T22:39:42Z",
      "side": 1,
      "message": "Possibly I am doing something wrong, but with the following in values.yaml:\nservice:\n    type: ClusterIP\n    name: dcaemod-designtool\n    ports:\n    - name: http\n      port: 8080\n\nI get the following k8s spec:\napiVersion: v1\nkind: Service\nmetadata:\n\n  name: dcaemod-designtool\n  namespace: onap\n  labels:\n    app.kubernetes.io/name: dcaemod-designtool\n    helm.sh/chart: dcaemod-designtool-6.0.0\n    app.kubernetes.io/instance: testmod\n    app.kubernetes.io/managed-by: Tiller\nspec:\n  ports:\n\n    - port: 8080\n      targetPort: http\n      name: http\n  type: ClusterIP\n  selector:\n    app.kubernetes.io/name: dcaemod-designtool\n    app.kubernetes.io/instance: testmod\n\nThe targetPort should be a port number, not a copy of the port name.   The template should probably not generate the targetPort at all.  Rather, if it\u0027s desired to have the port and targetPort be different, the values.yaml should supply a targetPort value.   Otherwise, targetPort can be omitted, and k8s will default it to the same value as port.\n\nWhen I attempt to deploy the chart, I get the following error:\nError: release testmod failed: Service \"dcaemod-distributor-api\" is invalid: spec.ports: Required value\n\nSee _service.tpl line 68 for the targetPort setting.\n\nAlso I note that the selectors assume labeling on the target deployment that follow a different convention from what we have used in the past.  \n\nAt the head of the master branch, I don\u0027t see any project using this template yet.\nI propose not to use the service template in the Frankfurt release, unless there is a simple fix I can make to my values.yaml or service.yaml file.",
      "parentUuid": "01a04862_88933ace",
      "revId": "716cb4803746cf62f10eb194b0f416bde861ca4e",
      "serverId": "14b4e41f-c4e3-4fb9-9955-6a9b5656895a",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "02050dbd_47247460",
        "filename": "kubernetes/dcaemod/components/dcaemod-designtool/templates/service.yaml",
        "patchSetId": 2
      },
      "lineNbr": 19,
      "author": {
        "id": 4965
      },
      "writtenOn": "2020-02-27T15:59:43Z",
      "side": 1,
      "message": "Have you tested that it\u0027s actually a bug and sth is not working?\nAccording to kubernetes doc:\nhttps://kubernetes.io/docs/reference/generated/kubernetes-api/v1.17/#serviceport-v1-core\nThis field can be either a number or a name",
      "parentUuid": "4bafda3e_81ae8b66",
      "revId": "716cb4803746cf62f10eb194b0f416bde861ca4e",
      "serverId": "14b4e41f-c4e3-4fb9-9955-6a9b5656895a",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "f0362ccd_75bdb51a",
        "filename": "kubernetes/dcaemod/components/dcaemod-designtool/templates/service.yaml",
        "patchSetId": 2
      },
      "lineNbr": 19,
      "author": {
        "id": 511
      },
      "writtenOn": "2020-02-27T16:33:03Z",
      "side": 1,
      "message": "Yes, I tried installing using the charts generated with the service template, and reported the error in my previous comment.   \nError: release testmod failed: Service \"dcaemod-distributor-api\" is invalid: spec.ports: Required value\n\nIt looks to me like \"ports\" is present in the spec.  There are some extraneous blank lines in the output, but I don\u0027t think those are the issue. \n\nIf I supply the rendered output directly to kubernetes (with kubectl apply or create), it creates a service.",
      "parentUuid": "02050dbd_47247460",
      "revId": "716cb4803746cf62f10eb194b0f416bde861ca4e",
      "serverId": "14b4e41f-c4e3-4fb9-9955-6a9b5656895a",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "3739e257_62cc4a50",
        "filename": "kubernetes/dcaemod/components/dcaemod-distributor-api/templates/deployment.yaml",
        "patchSetId": 2
      },
      "lineNbr": 18,
      "author": {
        "id": 4965
      },
      "writtenOn": "2020-02-21T23:46:38Z",
      "side": 1,
      "message": "please use apps/v1 version",
      "revId": "716cb4803746cf62f10eb194b0f416bde861ca4e",
      "serverId": "14b4e41f-c4e3-4fb9-9955-6a9b5656895a",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "929f0d79_ca1262df",
        "filename": "kubernetes/dcaemod/components/dcaemod-distributor-api/templates/deployment.yaml",
        "patchSetId": 2
      },
      "lineNbr": 18,
      "author": {
        "id": 511
      },
      "writtenOn": "2020-02-26T22:39:42Z",
      "side": 1,
      "message": "Addressed in patchset #3",
      "parentUuid": "3739e257_62cc4a50",
      "revId": "716cb4803746cf62f10eb194b0f416bde861ca4e",
      "serverId": "14b4e41f-c4e3-4fb9-9955-6a9b5656895a",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "ef0bfb63_d8b5e8e5",
        "filename": "kubernetes/dcaemod/components/dcaemod-distributor-api/values.yaml",
        "patchSetId": 2
      },
      "lineNbr": 48,
      "author": {
        "id": 4965
      },
      "writtenOn": "2020-02-21T23:46:38Z",
      "side": 1,
      "message": "awwww ingress enabled by default awesome!:)",
      "revId": "716cb4803746cf62f10eb194b0f416bde861ca4e",
      "serverId": "14b4e41f-c4e3-4fb9-9955-6a9b5656895a",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "85e5a698_970868f7",
        "filename": "kubernetes/dcaemod/components/dcaemod-nifi-registry/templates/deployment.yaml",
        "patchSetId": 2
      },
      "lineNbr": 75,
      "author": {
        "id": 4965
      },
      "writtenOn": "2020-02-21T23:46:38Z",
      "side": 1,
      "message": "Please use secrets to access this.\nWe have also a new secret template which you can use.",
      "revId": "716cb4803746cf62f10eb194b0f416bde861ca4e",
      "serverId": "14b4e41f-c4e3-4fb9-9955-6a9b5656895a",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "c172704d_005a8cb1",
        "filename": "kubernetes/dcaemod/components/dcaemod-nifi-registry/templates/deployment.yaml",
        "patchSetId": 2
      },
      "lineNbr": 75,
      "author": {
        "id": 511
      },
      "writtenOn": "2020-02-27T13:30:31Z",
      "side": 1,
      "message": "Done in patchset 4",
      "parentUuid": "85e5a698_970868f7",
      "revId": "716cb4803746cf62f10eb194b0f416bde861ca4e",
      "serverId": "14b4e41f-c4e3-4fb9-9955-6a9b5656895a",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "496faa68_96dd66ac",
        "filename": "kubernetes/dcaemod/components/dcaemod-onboarding-api/templates/deployment.yaml",
        "patchSetId": 2
      },
      "lineNbr": 73,
      "author": {
        "id": 4965
      },
      "writtenOn": "2020-02-21T23:46:38Z",
      "side": 1,
      "message": "Password should be passed as a secret",
      "revId": "716cb4803746cf62f10eb194b0f416bde861ca4e",
      "serverId": "14b4e41f-c4e3-4fb9-9955-6a9b5656895a",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "d8f4ed44_664b7d64",
        "filename": "kubernetes/dcaemod/components/dcaemod-onboarding-api/values.yaml",
        "patchSetId": 2
      },
      "lineNbr": 72,
      "author": {
        "id": 4965
      },
      "writtenOn": "2020-02-21T23:46:38Z",
      "side": 1,
      "message": "Don\u0027t hardcode postgres password use common secret template. Let me know if you need help with this",
      "revId": "716cb4803746cf62f10eb194b0f416bde861ca4e",
      "serverId": "14b4e41f-c4e3-4fb9-9955-6a9b5656895a",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "e904d4ad_c7159d9d",
        "filename": "kubernetes/dcaemod/components/dcaemod-onboarding-api/values.yaml",
        "patchSetId": 2
      },
      "lineNbr": 72,
      "author": {
        "id": 511
      },
      "writtenOn": "2020-02-27T23:16:42Z",
      "side": 1,
      "message": "Yes, I need help!\n\nI did not find any examples of other projects using the common postgres charts with templates. If you can point me to one, that might be sufficient.\n\nI\u0027m not able to retrieve the postgres secret from the environment variable.\n\nI followed the pattern in the common postgres _deployment.tpl template to try to retrieve the postgres root password in my deployment, like this:\n          env:\n            - name: PG_ROOT_PW\n              {{- include \"common.secret.envFromSecret\" (dict \"global\" . \"uid\" (include \"common.postgres.secret.rootPassUID\" .) \"key\" \"password\") | indent 14 }}\n           \nWhen this is rendered, the secretKeyRef.name field is empty:\n          env:\n            - name: PG_ROOT_PW              \n              valueFrom:\n                secretKeyRef:\n                  name: \n                  key: password\n\nI suspect I need to pass something other than \".\" as the value for \"global\", but I don\u0027t know what it is. Or possibly I need to put something else in my deployment to make the resolution of the secret name work properly.   Please let me know.",
      "parentUuid": "d8f4ed44_664b7d64",
      "revId": "716cb4803746cf62f10eb194b0f416bde861ca4e",
      "serverId": "14b4e41f-c4e3-4fb9-9955-6a9b5656895a",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "4f2a2086_00d7447d",
        "filename": "kubernetes/dcaemod/components/dcaemod-onboarding-api/values.yaml",
        "patchSetId": 2
      },
      "lineNbr": 72,
      "author": {
        "id": 93
      },
      "writtenOn": "2020-02-28T18:47:23Z",
      "side": 1,
      "message": "Krzysztof - Jack informed there is an issue/bug to use the new template/generated password for postgres (https://jira.onap.org/browse/OOM-2317). \n\nAs we are litterally few days from M4, I would suggest deferring work to refactor current chart for new templates part of subsequent delivery, that way we are not blocked from delivering MOD for Frankfurt. We are currently working to release the dependent MOD images - once done, the verify job should succeed. Any pending review/comments from security standpoint could be tracked as separate jira and addressed post M4.",
      "parentUuid": "e904d4ad_c7159d9d",
      "revId": "716cb4803746cf62f10eb194b0f416bde861ca4e",
      "serverId": "14b4e41f-c4e3-4fb9-9955-6a9b5656895a",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "823bc2f5_822debbd",
        "filename": "kubernetes/dcaemod/components/dcaemod-onboarding-api/values.yaml",
        "patchSetId": 2
      },
      "lineNbr": 72,
      "author": {
        "id": 511
      },
      "writtenOn": "2020-02-28T22:46:52Z",
      "side": 1,
      "message": "The previous comment was based on letting the postgres chart create the secrets, and having the client application use those secrets to set the appropriate environment variables.\n\nThe closest example I could find was the pending review for dmaap-dr\u0027s use of mariadb-galera, where the application creates the secret (allowing the password to be generated) and configures postgres to use that secret as an \"external secret\".   I am now taking the same approach with postgres for dcaemod-onboarding-api.\n\nUnfortunately, the postgres container has a problem with certain special characters in the password, due to the way it converts the environment variable containing the password into the SQL instruction that actually sets the password.  Our password generation does not avoid these characters.   I have raised OOM-2317 to track this.\n\nFor R6, I propose continuing to set the database passwords explicitly in values.yaml.",
      "parentUuid": "e904d4ad_c7159d9d",
      "revId": "716cb4803746cf62f10eb194b0f416bde861ca4e",
      "serverId": "14b4e41f-c4e3-4fb9-9955-6a9b5656895a",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "f2f045e8_82abc71e",
        "filename": "kubernetes/dcaemod/components/dcaemod-runtime-api/templates/deployment.yaml",
        "patchSetId": 2
      },
      "lineNbr": 57,
      "author": {
        "id": 4965
      },
      "writtenOn": "2020-02-21T23:46:38Z",
      "side": 1,
      "message": "secret",
      "revId": "716cb4803746cf62f10eb194b0f416bde861ca4e",
      "serverId": "14b4e41f-c4e3-4fb9-9955-6a9b5656895a",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "e42e4f2e_7264b483",
        "filename": "kubernetes/dcaemod/components/dcaemod-runtime-api/templates/deployment.yaml",
        "patchSetId": 2
      },
      "lineNbr": 57,
      "author": {
        "id": 511
      },
      "writtenOn": "2020-02-27T13:30:31Z",
      "side": 1,
      "message": "Done in patchset 4",
      "parentUuid": "f2f045e8_82abc71e",
      "revId": "716cb4803746cf62f10eb194b0f416bde861ca4e",
      "serverId": "14b4e41f-c4e3-4fb9-9955-6a9b5656895a",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "f1d3c8ec_4547f0e2",
        "filename": "kubernetes/dcaemod/components/dcaemod-runtime-api/templates/deployment.yaml",
        "patchSetId": 2
      },
      "lineNbr": 59,
      "author": {
        "id": 4965
      },
      "writtenOn": "2020-02-21T23:46:38Z",
      "side": 1,
      "message": "secret",
      "revId": "716cb4803746cf62f10eb194b0f416bde861ca4e",
      "serverId": "14b4e41f-c4e3-4fb9-9955-6a9b5656895a",
      "unresolved": false
    },
    {
      "key": {
        "uuid": "31abecce_1d900950",
        "filename": "kubernetes/dcaemod/components/dcaemod-runtime-api/templates/deployment.yaml",
        "patchSetId": 2
      },
      "lineNbr": 59,
      "author": {
        "id": 511
      },
      "writtenOn": "2020-02-27T13:30:31Z",
      "side": 1,
      "message": "Done in patchset 4",
      "parentUuid": "f1d3c8ec_4547f0e2",
      "revId": "716cb4803746cf62f10eb194b0f416bde861ca4e",
      "serverId": "14b4e41f-c4e3-4fb9-9955-6a9b5656895a",
      "unresolved": false
    }
  ]
}